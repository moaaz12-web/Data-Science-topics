{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moaaz12-web/Data-Science-topics/blob/main/Regret_detection_and_regret_domain_identification_using_ML_algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBfDW_8rOWMx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8XEIgg-PzAF",
        "outputId": "28b43077-69c5-46d3-f973-d2f75029075c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "45R-XnN4QnCI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SinRHDSkQuX3"
      },
      "outputs": [],
      "source": [
        "df_domain = pd.read_excel('/content/drive/MyDrive/regret/Testing_Regret_domain.xlsx')\n",
        "df_label = pd.read_excel('/content/Testing_Regret_data_with_reddit12.xlsx')\n",
        "df_data = pd.read_excel('/content/drive/MyDrive/regret/Testing_Regret_data.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCFW6aDxHjRZ",
        "outputId": "007f5747-0003-4bb8-a433-5a139e7c1972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaaSmuX5ImfW"
      },
      "source": [
        "# using ml models for detecting the domain only using tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJlTnBysUU4o",
        "outputId": "8be53e80-d486-4ebd-a35e-e568c48903dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Multinomial Naive Bayes\n",
            "Mean Accuracy: 0.3124693176239568\n",
            "Mean Precision: 0.44002161762102115\n",
            "Mean Recall: 0.3892966360856269\n",
            "Mean F1 Score: 0.3135848539152429\n",
            "\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Mean Accuracy: 0.36794305351006384\n",
            "Mean Precision: 0.3909947118437814\n",
            "Mean Recall: 0.36794305351006384\n",
            "Mean F1 Score: 0.33800162802207484\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Mean Accuracy: 0.33038782523318605\n",
            "Mean Precision: 0.3388123764590718\n",
            "Mean Recall: 0.33038782523318605\n",
            "Mean F1 Score: 0.29860318919317946\n",
            "\n",
            "\n",
            "Model: Logistic Regression\n",
            "Mean Accuracy: 0.37358861070201277\n",
            "Mean Precision: 0.3708398830425774\n",
            "Mean Recall: 0.37358861070201277\n",
            "Mean F1 Score: 0.3453501090621169\n",
            "\n",
            "\n",
            "Model: XGBoost\n",
            "Mean Accuracy: 0.3321060382916053\n",
            "Mean Precision: 0.3222844383395065\n",
            "Mean Recall: 0.3321060382916053\n",
            "Mean F1 Score: 0.3074411830176596\n",
            "\n",
            "\n",
            "Model: AdaBoost\n",
            "Mean Accuracy: 0.28252331860579283\n",
            "Mean Precision: 0.31004852126929255\n",
            "Mean Recall: 0.28252331860579283\n",
            "Mean F1 Score: 0.26727894401729607\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from warnings import simplefilter\n",
        "\n",
        "# Suppress the warning for simplicity\n",
        "# simplefilter(\"ignore\", category=UndefinedMetricWarning)\n",
        "\n",
        "# Step 2: Preprocessing (Remove NaN values)\n",
        "df_domain.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Text feature extraction and representation techniques\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(df_domain['Hindi'])\n",
        "\n",
        "# Encode the class labels into integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df_domain['Domain'])\n",
        "\n",
        "# Step 4: Divide data into K folds (e.g., 5-fold cross-validation)\n",
        "kf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "# Step 5: Initialize a list of machine learning models\n",
        "models = [\n",
        "    ('Multinomial Naive Bayes', MultinomialNB()),\n",
        "    ('Support Vector Machine', SVC()),\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('Logistic Regression', LogisticRegression()),\n",
        "    ('XGBoost', XGBClassifier(\n",
        "        n_estimators=100,  # Number of trees\n",
        "        max_depth=3,       # Maximum tree depth\n",
        "        learning_rate=0.1, # Learning rate\n",
        "        subsample=0.8,     # Fraction of samples used for tree building\n",
        "        colsample_bytree=0.8  # Fraction of features used for tree building\n",
        "    )),\n",
        "    ('AdaBoost', AdaBoostClassifier())\n",
        "]\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "for model_name, model in models:\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Accuracy of the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print the mean evaluation metrics for each model\n",
        "    mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "    mean_precision = sum(precision_scores) / len(precision_scores)\n",
        "    mean_recall = sum(recall_scores) / len(recall_scores)\n",
        "    mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Mean Accuracy:\", mean_accuracy)\n",
        "    print(\"Mean Precision:\", mean_precision)\n",
        "    print(\"Mean Recall:\", mean_recall)\n",
        "    print(\"Mean F1 Score:\", mean_f1)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jICQuXD6HQ-2"
      },
      "source": [
        "# using ml models for predicting domain using bag of words + ngram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMZ_HLuOHXnr",
        "outputId": "82971841-7a98-4426-e9e0-39b96d3335d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Multinomial Naive Bayes\n",
            "Mean Accuracy: 0.32179675994108986\n",
            "Mean Precision: 0.4153427361018864\n",
            "Mean Recall: 0.3583109675267649\n",
            "Mean F1 Score: 0.287996624442218\n",
            "\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Mean Accuracy: 0.2960235640648012\n",
            "Mean Precision: 0.37466954012418974\n",
            "Mean Recall: 0.3242542850984402\n",
            "Mean F1 Score: 0.27926427563605405\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Mean Accuracy: 0.3325969563082965\n",
            "Mean Precision: 0.3560837113970496\n",
            "Mean Recall: 0.3325969563082965\n",
            "Mean F1 Score: 0.3001475295436605\n",
            "\n",
            "\n",
            "Model: Logistic Regression\n",
            "Mean Accuracy: 0.34756995581737843\n",
            "Mean Precision: 0.35469034705696023\n",
            "Mean Recall: 0.34756995581737843\n",
            "Mean F1 Score: 0.3328403388679524\n",
            "\n",
            "\n",
            "Model: XGBoost\n",
            "Mean Accuracy: 0.3495336278841434\n",
            "Mean Precision: 0.35206584153156495\n",
            "Mean Recall: 0.3495336278841434\n",
            "Mean F1 Score: 0.32689360746444013\n",
            "\n",
            "\n",
            "Model: AdaBoost\n",
            "Mean Accuracy: 0.2911143838978891\n",
            "Mean Precision: 0.3188452768436723\n",
            "Mean Recall: 0.3010776181933351\n",
            "Mean F1 Score: 0.28076919201210154\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier  # Make sure you have XGBoost installed\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Step 2: Preprocessing (Remove NaN values)\n",
        "df_domain.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Text feature extraction and representation techniques using n-grams with Tfidf\n",
        "count_vectorizer = CountVectorizer(ngram_range=(1, 2))  # You can specify the n-gram range here\n",
        "X = count_vectorizer.fit_transform(df_domain['Hindi'])\n",
        "\n",
        "# Encode the class labels into integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df_domain['Domain'])\n",
        "\n",
        "kf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "# Step 5: Initialize a list of machine learning models\n",
        "models = [\n",
        "    ('Multinomial Naive Bayes', MultinomialNB()),\n",
        "    ('Support Vector Machine', SVC()),\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('Logistic Regression', LogisticRegression(max_iter=1200)),\n",
        "    ('XGBoost', XGBClassifier(\n",
        "        n_estimators=100,  # Number of trees\n",
        "        max_depth=3,       # Maximum tree depth\n",
        "        learning_rate=0.1, # Learning rate\n",
        "        subsample=0.8,     # Fraction of samples used for tree building\n",
        "        colsample_bytree=0.8  # Fraction of features used for tree building\n",
        "    )),\n",
        "    ('AdaBoost', AdaBoostClassifier())\n",
        "]\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "for model_name, model in models:\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Accuracy of the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print the mean evaluation metrics for each model\n",
        "    mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "    mean_precision = sum(precision_scores) / len(precision_scores)\n",
        "    mean_recall = sum(recall_scores) / len(recall_scores)\n",
        "    mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Mean Accuracy:\", mean_accuracy)\n",
        "    print(\"Mean Precision:\", mean_precision)\n",
        "    print(\"Mean Recall:\", mean_recall)\n",
        "    print(\"Mean F1 Score:\", mean_f1)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxKdL0BMrkUg"
      },
      "source": [
        "# using ml models for predicting domain only using tfidf + ngram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT2mHpQ2rn5F",
        "outputId": "4f3ab7f2-94d5-441e-9f1d-1809de3f0d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Multinomial Naive Bayes\n",
            "Mean Accuracy: 0.27810505645557193\n",
            "Mean Precision: 0.4508276811509451\n",
            "Mean Recall: 0.377478905486975\n",
            "Mean F1 Score: 0.27148462881899565\n",
            "\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Mean Accuracy: 0.3505154639175258\n",
            "Mean Precision: 0.45516554171927986\n",
            "Mean Recall: 0.3718764819421749\n",
            "Mean F1 Score: 0.325065197492371\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Mean Accuracy: 0.3335787923416789\n",
            "Mean Precision: 0.359335152041314\n",
            "Mean Recall: 0.3335787923416789\n",
            "Mean F1 Score: 0.2979203719974018\n",
            "\n",
            "\n",
            "Model: Logistic Regression\n",
            "Mean Accuracy: 0.3738340697103584\n",
            "Mean Precision: 0.4092638858822564\n",
            "Mean Recall: 0.37972205086881866\n",
            "Mean F1 Score: 0.33999956787698377\n",
            "\n",
            "\n",
            "Model: XGBoost\n",
            "Mean Accuracy: 0.3335787923416789\n",
            "Mean Precision: 0.32811628698535755\n",
            "Mean Recall: 0.3335787923416789\n",
            "Mean F1 Score: 0.3086798374925735\n",
            "\n",
            "\n",
            "Model: AdaBoost\n",
            "Mean Accuracy: 0.2707412862052037\n",
            "Mean Precision: 0.2888219115953444\n",
            "Mean Recall: 0.2707412862052037\n",
            "Mean F1 Score: 0.24966774988472795\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier  # Make sure you have XGBoost installed\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Step 2: Preprocessing (Remove NaN values)\n",
        "df_domain.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Text feature extraction and representation techniques using n-grams with Tfidf\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # You can specify the n-gram range here\n",
        "X = tfidf_vectorizer.fit_transform(df_domain['Hindi'])\n",
        "\n",
        "# Encode the class labels into integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df_domain['Domain'])\n",
        "\n",
        "kf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "# Step 5: Initialize a list of machine learning models\n",
        "models = [\n",
        "    ('Multinomial Naive Bayes', MultinomialNB()),\n",
        "    ('Support Vector Machine', SVC()),\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('Logistic Regression', LogisticRegression(max_iter=1200)),\n",
        "    ('XGBoost', XGBClassifier(\n",
        "        n_estimators=100,  # Number of trees\n",
        "        max_depth=3,       # Maximum tree depth\n",
        "        learning_rate=0.1, # Learning rate\n",
        "        subsample=0.8,     # Fraction of samples used for tree building\n",
        "        colsample_bytree=0.8  # Fraction of features used for tree building\n",
        "    )),\n",
        "    ('AdaBoost', AdaBoostClassifier())\n",
        "]\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "for model_name, model in models:\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Accuracy of the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print the mean evaluation metrics for each model\n",
        "    mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "    mean_precision = sum(precision_scores) / len(precision_scores)\n",
        "    mean_recall = sum(recall_scores) / len(recall_scores)\n",
        "    mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Mean Accuracy:\", mean_accuracy)\n",
        "    print(\"Mean Precision:\", mean_precision)\n",
        "    print(\"Mean Recall:\", mean_recall)\n",
        "    print(\"Mean F1 Score:\", mean_f1)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUnZ-s6WIxns"
      },
      "source": [
        "# using ml models for detecting the regret type using tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWMWrzZ3XHbF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# HYPER PARAMETERS DEFINITION\n",
        "\n",
        "# Define hyperparameters for each model\n",
        "param_grid_nb = {'alpha': [0.1, 0.5, 1.0]}\n",
        "param_grid_svc = {'C': [10, 100]}\n",
        "param_grid_rf = {'n_estimators': [ 100, 200], 'max_depth': [10, 20]}\n",
        "param_grid_lr = {'C': [0.01, 0.1, 1, 10]}\n",
        "param_grid_xgb = {'n_estimators': [100, 200], 'max_depth': [5, 7], 'learning_rate': [0.05, 0.1]}\n",
        "param_grid_ada = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgZtS5ssrfrB",
        "outputId": "197f29d0-66c0-4bb6-f8fc-22a5386afad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Multinomial Naive Bayes\n",
            "Mean Accuracy: 0.6317755039972194\n",
            "Mean Precision: 0.6490687988701637\n",
            "Mean Recall: 0.49409190371991246\n",
            "Mean F1 Score: 0.561001122030949\n",
            "Best Hyperparameters: {'alpha': 1.0}\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Mean Accuracy: 0.659929614181439\n",
            "Mean Precision: 0.6848545951450625\n",
            "Mean Recall: 0.5312910284463894\n",
            "Mean F1 Score: 0.5981282054601428\n",
            "Best Hyperparameters: {'max_depth': 20, 'n_estimators': 200}\n",
            "\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Mean Accuracy: 0.6528382429614181\n",
            "Mean Precision: 0.6440719599399942\n",
            "Mean Recall: 0.6065645514223195\n",
            "Mean F1 Score: 0.6246534197479063\n",
            "Best Hyperparameters: {'C': 100}\n",
            "\n",
            "\n",
            "Model: Logistic Regression\n",
            "Mean Accuracy: 0.6497075947167188\n",
            "Mean Precision: 0.6453316735042005\n",
            "Mean Recall: 0.5886214442013129\n",
            "Mean F1 Score: 0.6156038995573005\n",
            "Best Hyperparameters: {'C': 1}\n",
            "\n",
            "\n",
            "Model: XGBoost\n",
            "Mean Accuracy: 0.6549250521376433\n",
            "Mean Precision: 0.6533381663755409\n",
            "Mean Recall: 0.5881838074398249\n",
            "Mean F1 Score: 0.618935826483159\n",
            "Best Hyperparameters: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}\n",
            "\n",
            "\n",
            "Model: AdaBoost\n",
            "Mean Accuracy: 0.6286574556830031\n",
            "Mean Precision: 0.6223053447836702\n",
            "Mean Recall: 0.5601750547045952\n",
            "Mean F1 Score: 0.5894601238058543\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'n_estimators': 200}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier  # Make sure you have XGBoost installed\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Step 2: Preprocessing (Remove NaN values)\n",
        "df_label.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Text feature extraction and representation techniques\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(df_label['Hindi'])\n",
        "\n",
        "# Encode the class labels into integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df_label['Regret'])\n",
        "\n",
        "# Step 4: Divide data into K folds (e.g., 5-fold cross-validation)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "# Updated list of models with hyperparameters\n",
        "models = [\n",
        "    ('Multinomial Naive Bayes', GridSearchCV(MultinomialNB(), param_grid_nb, cv=3)),\n",
        "    ('Random Forest', GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=3)),\n",
        "    ('Support Vector Machine', GridSearchCV(SVC(), param_grid_svc, cv=3)),\n",
        "    ('Logistic Regression', GridSearchCV(LogisticRegression(), param_grid_lr, cv=3)),\n",
        "    ('XGBoost', GridSearchCV(XGBClassifier(), param_grid_xgb, cv=3)),\n",
        "    ('AdaBoost', GridSearchCV(AdaBoostClassifier(), param_grid_ada, cv=3))\n",
        "]\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "for model_name, model in models:\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the model with hyperparameter tuning\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Accuracy of the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print the mean evaluation metrics for each model\n",
        "    mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "    mean_precision = sum(precision_scores) / len(precision_scores)\n",
        "    mean_recall = sum(recall_scores) / len(recall_scores)\n",
        "    mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Mean Accuracy:\", mean_accuracy)\n",
        "    print(\"Mean Precision:\", mean_precision)\n",
        "    print(\"Mean Recall:\", mean_recall)\n",
        "    print(\"Mean F1 Score:\", mean_f1)\n",
        "    print(\"Best Hyperparameters:\", model.best_params_)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n79A1IXr_ei"
      },
      "source": [
        "# using ml models for detecting the regret type using tfidf + ngram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPpFMW0fYXmN"
      },
      "outputs": [],
      "source": [
        "del models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5EHrtOjVGPA",
        "outputId": "e6b70503-d2a7-4090-e476-ab785bf38670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Multinomial Naive Bayes\n",
            "Mean Accuracy: 0.6461619603199017\n",
            "Mean Precision: 0.692341824880499\n",
            "Mean Recall: 0.46565393189189064\n",
            "Mean F1 Score: 0.5558071157845837\n",
            "Best Hyperparameters: {'alpha': 0.5}\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Mean Accuracy: 0.6211428033217464\n",
            "Mean Precision: 0.7218042825471144\n",
            "Mean Recall: 0.3352199240535143\n",
            "Mean F1 Score: 0.4572730726064059\n",
            "Best Hyperparameters: {'max_depth': 20, 'n_estimators': 200}\n",
            "\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Mean Accuracy: 0.665135802701052\n",
            "Mean Precision: 0.6690240588652929\n",
            "Mean Recall: 0.5881725362516282\n",
            "Mean F1 Score: 0.6258482402331572\n",
            "Best Hyperparameters: {'C': 10}\n",
            "\n",
            "\n",
            "Model: Logistic Regression\n",
            "Mean Accuracy: 0.6545012879607953\n",
            "Mean Precision: 0.6612636737217518\n",
            "Mean Recall: 0.5636583534811105\n",
            "Mean F1 Score: 0.6081422504097751\n",
            "Best Hyperparameters: {'C': 1}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier  # Make sure you have XGBoost installed\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Step 2: Preprocessing (Remove NaN values)\n",
        "df_label.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Text feature extraction and representation techniques using n-grams with Tfidf\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # You can specify the n-gram range here\n",
        "X = tfidf_vectorizer.fit_transform(df_label['Hindi'])\n",
        "\n",
        "\n",
        "# Encode the class labels into integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df_label['Regret'])\n",
        "\n",
        "# Step 4: Divide data into K folds (e.g., 5-fold cross-validation)\n",
        "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "# Updated list of models with hyperparameters\n",
        "models = [\n",
        "    ('Multinomial Naive Bayes', GridSearchCV(MultinomialNB(), param_grid_nb, cv=3)),\n",
        "    ('Random Forest', GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=3)),\n",
        "    ('Support Vector Machine', GridSearchCV(SVC(), param_grid_svc, cv=3)),\n",
        "    ('Logistic Regression', GridSearchCV(LogisticRegression(max_iter=1100), param_grid_lr, cv=3)),\n",
        "    # ('XGBoost', GridSearchCV(XGBClassifier(), param_grid_xgb, cv=3)),\n",
        "    # ('AdaBoost', GridSearchCV(AdaBoostClassifier(), param_grid_ada, cv=3))\n",
        "]\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "for model_name, model in models:\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the model with hyperparameter tuning\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Accuracy of the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print the mean evaluation metrics for each model\n",
        "    mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "    mean_precision = sum(precision_scores) / len(precision_scores)\n",
        "    mean_recall = sum(recall_scores) / len(recall_scores)\n",
        "    mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Mean Accuracy:\", mean_accuracy)\n",
        "    print(\"Mean Precision:\", mean_precision)\n",
        "    print(\"Mean Recall:\", mean_recall)\n",
        "    print(\"Mean F1 Score:\", mean_f1)\n",
        "    print(\"Best Hyperparameters:\", model.best_params_)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ63kRRdHLJN",
        "outputId": "a2405dc7-3323-439e-896b-9bb7f02a8081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model:\n",
            "Mean Accuracy: 0.6555439974347755\n",
            "Mean Precision: 0.6524239757561936\n",
            "Mean Recall: 0.5938610498917596\n",
            "Mean F1 Score: 0.6214741090130529\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters for XGBoost\n",
        "param_grid_xgb = {'n_estimators': [100, 200],  'learning_rate': [0.01, 0.1]}\n",
        "\n",
        "# Initialize XGBoost model\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the XGBoost model with hyperparameter tuning\n",
        "    xgb_grid = GridSearchCV(xgb_model, param_grid_xgb, cv=3)\n",
        "    xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    y_pred = xgb_grid.predict(X_test)\n",
        "\n",
        "    # Accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate and print the mean evaluation metrics for XGBoost model\n",
        "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "mean_precision = sum(precision_scores) / len(precision_scores)\n",
        "mean_recall = sum(recall_scores) / len(recall_scores)\n",
        "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "print(\"XGBoost Model:\")\n",
        "print(\"Mean Accuracy:\", mean_accuracy)\n",
        "print(\"Mean Precision:\", mean_precision)\n",
        "print(\"Mean Recall:\", mean_recall)\n",
        "print(\"Mean F1 Score:\", mean_f1)\n",
        "print(\"Best Hyperparameters:\", xgb_grid.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqx8lSRUSrq5",
        "outputId": "46a0dac6-e07b-4eaa-808f-17ddc48b403b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Model:\n",
            "Mean Accuracy: 0.6175997044460673\n",
            "Mean Precision: 0.6092268380972398\n",
            "Mean Recall: 0.5531619651354356\n",
            "Mean F1 Score: 0.5794311612134995\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'n_estimators': 50}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Define hyperparameters for AdaBoost\n",
        "param_grid_ada = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
        "\n",
        "# Initialize AdaBoost model\n",
        "ada_model = AdaBoostClassifier()\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "accuracy_scores_ada = []\n",
        "precision_scores_ada = []\n",
        "recall_scores_ada = []\n",
        "f1_scores_ada = []\n",
        "\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the AdaBoost model with hyperparameter tuning\n",
        "    ada_grid = GridSearchCV(ada_model, param_grid_ada, cv=3)\n",
        "    ada_grid.fit(X_train, y_train)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    y_pred_ada = ada_grid.predict(X_test)\n",
        "\n",
        "    # Accuracy of the model\n",
        "    accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
        "    accuracy_scores_ada.append(accuracy_ada)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score\n",
        "    precision_ada = precision_score(y_test, y_pred_ada)\n",
        "    recall_ada = recall_score(y_test, y_pred_ada)\n",
        "    f1_ada = f1_score(y_test, y_pred_ada)\n",
        "\n",
        "    precision_scores_ada.append(precision_ada)\n",
        "    recall_scores_ada.append(recall_ada)\n",
        "    f1_scores_ada.append(f1_ada)\n",
        "\n",
        "# Calculate and print the mean evaluation metrics for AdaBoost model\n",
        "mean_accuracy_ada = sum(accuracy_scores_ada) / len(accuracy_scores_ada)\n",
        "mean_precision_ada = sum(precision_scores_ada) / len(precision_scores_ada)\n",
        "mean_recall_ada = sum(recall_scores_ada) / len(recall_scores_ada)\n",
        "mean_f1_ada = sum(f1_scores_ada) / len(f1_scores_ada)\n",
        "\n",
        "print(\"AdaBoost Model:\")\n",
        "print(\"Mean Accuracy:\", mean_accuracy_ada)\n",
        "print(\"Mean Precision:\", mean_precision_ada)\n",
        "print(\"Mean Recall:\", mean_recall_ada)\n",
        "print(\"Mean F1 Score:\", mean_f1_ada)\n",
        "print(\"Best Hyperparameters:\", ada_grid.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHdktI8rHAJr"
      },
      "source": [
        "# using ml models for detecting the regret type using bag of words + ngram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft7ADk-lYbaz"
      },
      "outputs": [],
      "source": [
        "del models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nal1WfSiC_KA",
        "outputId": "42c9f993-622f-4954-fb65-6f8434796758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Multinomial Naive Bayes\n",
            "Mean Accuracy: 0.6378226326790081\n",
            "Mean Precision: 0.6168538189341004\n",
            "Mean Recall: 0.6328229996217621\n",
            "Mean F1 Score: 0.6246991519353613\n",
            "Best Hyperparameters: {'alpha': 1.0}\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Mean Accuracy: 0.6071720878949427\n",
            "Mean Precision: 0.6967544426838878\n",
            "Mean Recall: 0.3142122017927785\n",
            "Mean F1 Score: 0.43240033598242555\n",
            "Best Hyperparameters: {'max_depth': 20, 'n_estimators': 200}\n",
            "\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Mean Accuracy: 0.6472070179448305\n",
            "Mean Precision: 0.6381405004819336\n",
            "Mean Recall: 0.6017557595050947\n",
            "Mean F1 Score: 0.6190562145055516\n",
            "Best Hyperparameters: {'C': 10}\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Mean Accuracy: 0.6524170430883091\n",
            "Mean Precision: 0.6452875071766568\n",
            "Mean Recall: 0.6004273283185201\n",
            "Mean F1 Score: 0.621944980703275\n",
            "Best Hyperparameters: {'C': 0.1}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier  # Make sure you have XGBoost installed\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Step 2: Preprocessing (Remove NaN values)\n",
        "df_label.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Text feature extraction and representation techniques using n-grams with Tfidf\n",
        "count_vectorizer = CountVectorizer(ngram_range=(1, 2))  # You can specify the n-gram range here\n",
        "X = count_vectorizer.fit_transform(df_label['Hindi'])\n",
        "\n",
        "\n",
        "# Encode the class labels into integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df_label['Regret'])\n",
        "\n",
        "# Step 4: Divide data into K folds (e.g., 5-fold cross-validation)\n",
        "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "# Updated list of models with hyperparameters\n",
        "models = [\n",
        "    ('Multinomial Naive Bayes', GridSearchCV(MultinomialNB(), param_grid_nb, cv=3)),\n",
        "    ('Random Forest', GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=3)),\n",
        "    ('Support Vector Machine', GridSearchCV(SVC(), param_grid_svc, cv=3)),\n",
        "    ('Logistic Regression', GridSearchCV(LogisticRegression(), param_grid_lr, cv=3)),\n",
        "    # ('XGBoost', GridSearchCV(XGBClassifier(), param_grid_xgb, cv=3)),\n",
        "    # ('AdaBoost', GridSearchCV(AdaBoostClassifier(), param_grid_ada, cv=3))\n",
        "]\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "for model_name, model in models:\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the model with hyperparameter tuning\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Accuracy of the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print the mean evaluation metrics for each model\n",
        "    mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "    mean_precision = sum(precision_scores) / len(precision_scores)\n",
        "    mean_recall = sum(recall_scores) / len(recall_scores)\n",
        "    mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Mean Accuracy:\", mean_accuracy)\n",
        "    print(\"Mean Precision:\", mean_precision)\n",
        "    print(\"Mean Recall:\", mean_recall)\n",
        "    print(\"Mean F1 Score:\", mean_f1)\n",
        "    print(\"Best Hyperparameters:\", model.best_params_)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsFdmDEWYcFj",
        "outputId": "1b977132-e9b0-4af3-d7c5-da64fe74a553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model:\n",
            "Mean Accuracy: 0.6453279753746801\n",
            "Mean Precision: 0.6358496442201127\n",
            "Mean Recall: 0.5986706490860784\n",
            "Mean F1 Score: 0.6163191205739308\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters for XGBoost\n",
        "param_grid_xgb = {'n_estimators': [100, 200],  'learning_rate': [0.01, 0.1]}\n",
        "\n",
        "# Initialize XGBoost model\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the XGBoost model with hyperparameter tuning\n",
        "    xgb_grid = GridSearchCV(xgb_model, param_grid_xgb, cv=3)\n",
        "    xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    y_pred = xgb_grid.predict(X_test)\n",
        "\n",
        "    # Accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate and print the mean evaluation metrics for XGBoost model\n",
        "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "mean_precision = sum(precision_scores) / len(precision_scores)\n",
        "mean_recall = sum(recall_scores) / len(recall_scores)\n",
        "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "print(\"XGBoost Model:\")\n",
        "print(\"Mean Accuracy:\", mean_accuracy)\n",
        "print(\"Mean Precision:\", mean_precision)\n",
        "print(\"Mean Recall:\", mean_recall)\n",
        "print(\"Mean F1 Score:\", mean_f1)\n",
        "print(\"Best Hyperparameters:\", xgb_grid.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn9gUlaQVveb",
        "outputId": "c9deeffa-3668-4c4b-fd44-698de7ee6af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Model:\n",
            "Mean Accuracy: 0.6092615508806479\n",
            "Mean Precision: 0.580888884178001\n",
            "Mean Recall: 0.6691246380010646\n",
            "Mean F1 Score: 0.6197566990984554\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Define hyperparameters for AdaBoost\n",
        "param_grid_ada = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
        "\n",
        "# Initialize AdaBoost model\n",
        "ada_model = AdaBoostClassifier()\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "accuracy_scores_ada = []\n",
        "precision_scores_ada = []\n",
        "recall_scores_ada = []\n",
        "f1_scores_ada = []\n",
        "\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the AdaBoost model with hyperparameter tuning\n",
        "    ada_grid = GridSearchCV(ada_model, param_grid_ada, cv=3)\n",
        "    ada_grid.fit(X_train, y_train)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    y_pred_ada = ada_grid.predict(X_test)\n",
        "\n",
        "    # Accuracy of the model\n",
        "    accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
        "    accuracy_scores_ada.append(accuracy_ada)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score\n",
        "    precision_ada = precision_score(y_test, y_pred_ada)\n",
        "    recall_ada = recall_score(y_test, y_pred_ada)\n",
        "    f1_ada = f1_score(y_test, y_pred_ada)\n",
        "\n",
        "    precision_scores_ada.append(precision_ada)\n",
        "    recall_scores_ada.append(recall_ada)\n",
        "    f1_scores_ada.append(f1_ada)\n",
        "\n",
        "# Calculate and print the mean evaluation metrics for AdaBoost model\n",
        "mean_accuracy_ada = sum(accuracy_scores_ada) / len(accuracy_scores_ada)\n",
        "mean_precision_ada = sum(precision_scores_ada) / len(precision_scores_ada)\n",
        "mean_recall_ada = sum(recall_scores_ada) / len(recall_scores_ada)\n",
        "mean_f1_ada = sum(f1_scores_ada) / len(f1_scores_ada)\n",
        "\n",
        "print(\"AdaBoost Model:\")\n",
        "print(\"Mean Accuracy:\", mean_accuracy_ada)\n",
        "print(\"Mean Precision:\", mean_precision_ada)\n",
        "print(\"Mean Recall:\", mean_recall_ada)\n",
        "print(\"Mean F1 Score:\", mean_f1_ada)\n",
        "print(\"Best Hyperparameters:\", ada_grid.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkPLZMsWVyjY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kqcn7Reelyhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCMJ94LXlydK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uaaSmuX5ImfW",
        "jICQuXD6HQ-2",
        "YxKdL0BMrkUg",
        "gUnZ-s6WIxns",
        "0n79A1IXr_ei",
        "DHdktI8rHAJr"
      ],
      "provenance": [],
      "mount_file_id": "16ZRsfs6HFTpr3mm5_b4b8DdJiYmD-SDC",
      "authorship_tag": "ABX9TyPtGszRy77K4VpKnDA9HFVG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}